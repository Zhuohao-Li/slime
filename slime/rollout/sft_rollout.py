import logging

from slime.utils.mask_utils import MultiTurnLossMaskGenerator
from slime.utils.processing_utils import load_processor, load_tokenizer, prepare_model_inputs

__all__ = ["generate_rollout"]

logger = logging.getLogger(__name__)


TOKENIZER = None
PROCESSOR = None
MASK_GENERATOR = None
SAMPLE_PRINTED = False


def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    """An example to implement the generate_rollout function for SFT rollout generation.
    Supports both text-only and multimodal (VLM) data.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_buffer: the data buffer to store the generated samples
        evaluation: bool, whether the rollout is for evaluation or not

    Returns:
        list[Sample]: a list of samples generated by the rollout
    """
    assert not evaluation
    assert args.rollout_global_dataset

    global TOKENIZER, PROCESSOR, MASK_GENERATOR, SAMPLE_PRINTED
    
    # Initialize tokenizer and processor
    if TOKENIZER is None:
        TOKENIZER = load_tokenizer(args.hf_checkpoint, trust_remote_code=True)
    
    if PROCESSOR is None:
        PROCESSOR = load_processor(args.hf_checkpoint, trust_remote_code=True)
        if PROCESSOR:
            logger.info("Loaded processor for VLM model")
        else:
            logger.info("No processor found, using text-only mode")

    if MASK_GENERATOR is None:
        MASK_GENERATOR = MultiTurnLossMaskGenerator(TOKENIZER, tokenizer_type=args.loss_mask_type)

    samples = data_buffer.get_samples(args.rollout_batch_size)

    for i, sample in enumerate(samples):
        (sample,) = sample
        messages = sample.prompt
        
        # For SFT training, we need both user question and assistant answer
        # Check if the data has the label (answer) and construct a complete conversation
        if hasattr(sample, 'label') and sample.label is not None:
            # If messages is already a list with user message, add assistant response
            if isinstance(messages, list) and len(messages) > 0:
                # Check if there's already an assistant message
                has_assistant = any(msg.get("role") == "assistant" for msg in messages)
                if not has_assistant:
                    # Add assistant's response from label
                    messages = messages + [{"role": "assistant", "content": sample.label}]
            else:
                # messages is a string, convert to full conversation
                messages = [
                    {"role": "user", "content": messages if isinstance(messages, str) else str(messages)},
                    {"role": "assistant", "content": sample.label}
                ]
        
        # Use prepare_model_inputs to handle both text-only and VLM data
        # This function properly handles chat templates, images, videos, etc.
        input_ids, extra_info = prepare_model_inputs(
            messages,
            TOKENIZER,
            PROCESSOR,
            sample.metadata if hasattr(sample, 'metadata') else None,
            args.apply_chat_template,
            args.apply_chat_template_kwargs,
        )
        
        # Store multimodal inputs in sample if present
        if extra_info.get("multimodal_inputs"):
            sample.multimodal_inputs = extra_info["multimodal_inputs"]
        
        # For VLM models, we need to create a text-only version of messages for loss mask generation
        # because MASK_GENERATOR doesn't understand multimodal content format
        has_multimodal = bool(extra_info.get("images") or extra_info.get("videos"))
        
        if has_multimodal:
            # Create text-only version of messages for mask generation
            text_only_messages = []
            for msg in messages:
                if isinstance(msg.get("content"), list):
                    # Extract text from multimodal content
                    text_parts = []
                    for item in msg["content"]:
                        if isinstance(item, dict) and item.get("type") == "text":
                            text_parts.append(item.get("text", ""))
                        elif isinstance(item, str):
                            text_parts.append(item)
                    text_only_messages.append({
                        "role": msg["role"],
                        "content": " ".join(text_parts)
                    })
                else:
                    text_only_messages.append(msg)
            
            # Generate loss mask using text-only messages
            _, loss_mask_text = MASK_GENERATOR.get_loss_mask(text_only_messages)
            
            # Use input_ids from prepare_model_inputs (includes image tokens)
            token_ids = input_ids
            
            # Adjust loss_mask to match the length with image tokens
            # Image tokens should not contribute to loss (mask = 0)
            diff = len(input_ids) - len(loss_mask_text)
            if diff > 0:
                # Prepend zeros for image tokens at the beginning
                loss_mask = [0] * diff + loss_mask_text
            elif diff < 0:
                # This shouldn't happen, but handle it gracefully
                logger.warning(f"Unexpected: input_ids shorter than text loss_mask by {-diff} tokens")
                loss_mask = loss_mask_text[-len(input_ids):]
            else:
                loss_mask = loss_mask_text
        else:
            # Text-only processing
            token_ids, loss_mask = MASK_GENERATOR.get_loss_mask(messages)
        
        # Calculate response length from loss mask
        response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]
        
        # Validate that we have a valid response
        if response_length == 0:
            logger.error(
                f"Response length is 0! messages={messages}, "
                f"loss_mask_sum={sum(loss_mask)}, loss_mask_len={len(loss_mask)}, "
                f"has_label={hasattr(sample, 'label')}, label={sample.label if hasattr(sample, 'label') else 'N/A'}"
            )
            raise ValueError("Response length cannot be 0 for SFT training. Make sure your dataset has answer/label field.")

        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]

        if i == 0 and not SAMPLE_PRINTED:
            has_images = bool(extra_info.get("images"))
            has_videos = bool(extra_info.get("videos"))
            logger.info(
                f"sft_rollout::generate_rollout example data: "
                f"messages={messages} | "
                f"token_length={len(token_ids)} | "
                f"response_length={response_length} | "
                f"loss_mask_sum={sum(loss_mask)} | "
                f"has_images={has_images} | "
                f"has_videos={has_videos} | "
                f"multimodal_inputs_keys={list(extra_info.get('multimodal_inputs', {}).keys())}"
            )
            SAMPLE_PRINTED = True

    return samples
