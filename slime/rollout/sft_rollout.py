import logging

from slime.utils.mask_utils import MultiTurnLossMaskGenerator
from slime.utils.processing_utils import load_processor, load_tokenizer, prepare_model_inputs

__all__ = ["generate_rollout"]

logger = logging.getLogger(__name__)


TOKENIZER = None
PROCESSOR = None
MASK_GENERATOR = None
SAMPLE_PRINTED = False


def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    """An example to implement the generate_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_buffer: the data buffer to store the generated samples
        evaluation: bool, whether the rollout is for evaluation or not

    Returns:
        list[Sample]: a list of samples generated by the rollout
    """
    assert not evaluation
    assert args.rollout_global_dataset

    global TOKENIZER, PROCESSOR, MASK_GENERATOR, SAMPLE_PRINTED
    if TOKENIZER is None:
        TOKENIZER = load_tokenizer(args.hf_checkpoint, trust_remote_code=True)
    
    if PROCESSOR is None:
        PROCESSOR = load_processor(args.hf_checkpoint, trust_remote_code=True)

    if MASK_GENERATOR is None:
        MASK_GENERATOR = MultiTurnLossMaskGenerator(TOKENIZER, tokenizer_type=args.loss_mask_type)

    samples = data_buffer.get_samples(args.rollout_batch_size)

    for i, sample in enumerate(samples):
        (sample,) = sample
        messages = sample.prompt
        metadata = getattr(sample, 'metadata', None) or {}
        tools = metadata.get("tools")
        
        if getattr(sample, 'label', None):
            if isinstance(messages, list) and messages:
                if not any(msg.get("role") == "assistant" for msg in messages):
                    messages = messages + [{"role": "assistant", "content": sample.label}]
            else:
                messages = [
                    {"role": "user", "content": messages if isinstance(messages, str) else str(messages)},
                    {"role": "assistant", "content": sample.label}
                ]
        
        input_ids, extra_info = prepare_model_inputs(
            messages, TOKENIZER, PROCESSOR, metadata,
            args.apply_chat_template, args.apply_chat_template_kwargs
        )
        
        if extra_info.get("multimodal_inputs"):
            sample.multimodal_inputs = extra_info["multimodal_inputs"]
        
        token_ids, loss_mask = MASK_GENERATOR.get_loss_mask_with_multimodal_alignment(
            messages, input_ids, bool(extra_info.get("images") or extra_info.get("videos")), tools=tools
        )
        
        response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]
        if response_length == 0:
            raise ValueError("Response length cannot be 0 for SFT training. Make sure your dataset has answer/label field.")

        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]

        if i == 0 and not SAMPLE_PRINTED:
            logger.info(
                f"sft_rollout::generate_rollout example data: {sample=} (raw){messages=} (raw){token_ids=} (raw){loss_mask=} {response_length=}"
            )
            SAMPLE_PRINTED = True

    return samples
